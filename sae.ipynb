{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "26128ab7-b996-4b92-89ad-a04d9dd47d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x12d4f05e0>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some notes from SAE tutorial on gemmascope https://colab.research.google.com/drive/17dQFYUYnuKnP6OwQPH9v_GSYUW5aj-Rp#scrollTo=12wF3f7o1Ni7\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# this is what you do if you only want inference (not training)\n",
    "# saves on memory usage\n",
    "torch.set_grad_enabled(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bcb172bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  7.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# every transformer has a tokenizer, so we load the one for the model we want to use\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")\n",
    "# this downloads the model (or loads it from disk cache)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1332811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_residual_activations(model, target_layer, inputs):\n",
    "  \"\"\"\n",
    "  This function allows us to gather activations for a specific layer on a model.\n",
    "  \n",
    "  Args:\n",
    "  - model: The model from which we want to gather activations.\n",
    "  - target_layer: The specific layer index for which we want to gather activations.\n",
    "  - inputs: The input data to be passed through the model.\n",
    "  \n",
    "  Returns:\n",
    "  - target_act: The activations of the specified layer.\n",
    "  \"\"\"\n",
    "  target_act = None\n",
    "  def gather_target_act_hook(mod, inputs, outputs):\n",
    "    nonlocal target_act # make sure we can modify the target_act from the outer scope\n",
    "    target_act = outputs[0]\n",
    "    return outputs\n",
    "  # we could also easily target the MLP layer\n",
    "  # handle = model.model.layers[target_layer].mlp.register_forward_hook(gather_mlp_output_hook)\n",
    "  handle = model.model.layers[target_layer].register_forward_hook(gather_target_act_hook)\n",
    "  _ = model.forward(inputs)\n",
    "  handle.remove()\n",
    "  return target_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "eef87c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7e62fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_breakdown(input_text, layer):\n",
    "  # combination of weights section\n",
    "  # we want to study what's happening in the model when we run some input text through it\n",
    "  \n",
    "  # the first step is to tokenize the input text\n",
    "  input_ids = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "  max_new_tokens = 1\n",
    "  outputs = model.generate(**input_ids, max_new_tokens=max_new_tokens)\n",
    "  generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "  print(\"Input text:\", input_text)\n",
    "  print(\"Generated text:\", generated_text)\n",
    "\n",
    "  target_act = gather_residual_activations(model, layer, input_ids['input_ids'])\n",
    "  sae_acts = sae.encode(target_act)\n",
    "\n",
    "  return input_text, input_ids, outputs, generated_text, target_act, sae_acts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10fc003",
   "metadata": {},
   "source": [
    "## SAE Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "54a5ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sae Stuff\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# We download the weights for the SAE we want to use\n",
    "# https://www.neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=\"google/gemma-scope-2b-pt-res\",\n",
    "    filename=\"layer_20/width_16k/average_l0_71/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v) for k, v in params.items()}\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "  def __init__(self, d_model, d_sae):\n",
    "    # Note that we initialise these to zeros because we're loading in pre-trained weights.\n",
    "    # If you want to train your own SAEs then we recommend using blah\n",
    "    super().__init__()\n",
    "    self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "    self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "    self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "    self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "    self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "  def encode(self, input_acts):\n",
    "    pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "    mask = (pre_acts > self.threshold)\n",
    "    acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "    return acts\n",
    "\n",
    "  def decode(self, acts):\n",
    "    return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "  def forward(self, acts):\n",
    "    acts = self.encode(acts)\n",
    "    recon = self.decode(acts)\n",
    "    return recon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "23132c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7fe8d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_layer_activation(model, target_layer, input_ids, steering, scale, max_new_tokens):\n",
    "    \"\"\"\n",
    "    Modify the activation of a specific feature in a given layer.\n",
    "    \n",
    "    Args:\n",
    "    - model: The LLM model\n",
    "    - target_layer: The index of the layer to modify\n",
    "    - input_ids: The input token IDs\n",
    "    - sae: The Sparse Autoencoder\n",
    "    - feature_index: The index of the feature to modify\n",
    "    - modification_value: The value to add to the feature's activation\n",
    "    \n",
    "    Returns:\n",
    "    - modified_output: The model's output after modification\n",
    "    \"\"\"\n",
    "    def capture_and_modify_hook(module, inputs, outputs):\n",
    "        print(\"hook\")\n",
    "        return outputs\n",
    "        # # Capture the original activation\n",
    "        # original_act = outputs[0].detach()        \n",
    "        # # Decode the modified activations\n",
    "        # modified_act = original_act #  + steering * scale\n",
    "        # # Return the modified activation\n",
    "        # return (modified_act,) + outputs[1:]\n",
    "\n",
    "    # # Register the hook\n",
    "    handle = model.model.layers[target_layer].register_forward_hook(capture_and_modify_hook)\n",
    "    \n",
    "    # Run the model with the modified activation\n",
    "    with torch.no_grad():\n",
    "        modified_output = model.generate(input_ids, max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # Remove the hook\n",
    "    handle.remove()\n",
    "    \n",
    "    return modified_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a7e96cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steering_vector(sae, feature_index, scale=500, normalize=True):\n",
    "    \"\"\"\n",
    "    Generate a steering vector for a specific feature in the Sparse Autoencoder (SAE).\n",
    "    \"\"\"\n",
    "    sae_acts = torch.zeros(1, sae.W_dec.shape[0], device=sae.W_dec.device)\n",
    "    sae_acts[0, feature_index] = scale\n",
    "    steering = sae.decode(sae_acts)\n",
    "    if normalize:\n",
    "        steering = steering / torch.norm(steering, dim=-1, keepdim=True)\n",
    "    return steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d292d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c03695bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "BreakdownResult = namedtuple('BreakdownResult', ['input_text', 'input_ids', 'outputs', 'generated_text', 'target_act', 'sae_acts'])\n",
    "\n",
    "\n",
    "def get_breakdown(input_text, layer):\n",
    "  # combination of weights section\n",
    "  # we want to study what's happening in the model when we run some input text through it\n",
    "  \n",
    "  # the first step is to tokenize the input text\n",
    "  input_ids = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "  max_new_tokens = 1\n",
    "  outputs = model.generate(**input_ids, max_new_tokens=max_new_tokens)\n",
    "  generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "  print(\"Input text:\", input_text)\n",
    "  print(\"Generated text:\", generated_text)\n",
    "\n",
    "  target_act = gather_residual_activations(model, layer, input_ids['input_ids'])\n",
    "  sae_acts = sae.encode(target_act)\n",
    "\n",
    "  return BreakdownResult(\n",
    "      input_text=input_text,\n",
    "      input_ids=input_ids,\n",
    "      outputs=outputs,\n",
    "      generated_text=generated_text,\n",
    "      target_act=target_act,\n",
    "      sae_acts=sae_acts\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "41afb29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: I went to Wells Fargo bank\n",
      "Generated text: I went to Wells Fargo bank to\n"
     ]
    }
   ],
   "source": [
    "layer = 20 # 20 is the embedding layer that we want to study with SAE\n",
    "\n",
    "adventerous = get_breakdown(\"I went to Wells Fargo bank\", layer)\n",
    "\n",
    "# shy = get_breakdown(\"I went to the river bank\", layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "92a30a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Token 2: \t\t<bos>\n",
      "1 Token 235285: \t\tI\n",
      "2 Token 3815: \t\t went\n",
      "3 Token 577: \t\t to\n",
      "4 Token 32059: \t\t Wells\n",
      "5 Token 86953: \t\t Fargo\n",
      "6 Token 5681: \t\t bank\n",
      "\n",
      "0 Token 2: \t\t<bos>\n",
      "1 Token 235285: \t\tI\n",
      "2 Token 3815: \t\t went\n",
      "3 Token 577: \t\t to\n",
      "4 Token 573: \t\t the\n",
      "5 Token 8540: \t\t river\n",
      "6 Token 5681: \t\t bank\n"
     ]
    }
   ],
   "source": [
    "import treescope\n",
    "\n",
    "print_input(adventerous.input_ids)\n",
    "print(\"\")\n",
    "print_input(shy.input_ids)\n",
    "\n",
    "idx = 6\n",
    "sae_release = \"gemma-2-2b\"\n",
    "layer = 20\n",
    "sae_id = f\"{layer}-gemmascope-res-16k\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a9462e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wells Fargo Bank\n",
      "tensor([89.2483, 73.0674, 42.8693, 41.5967, 39.5052, 38.9834, 37.6505, 34.5868])\n",
      "tensor([ 8993,  6631, 15920,  6071, 12559,  9768,  8476,  1692])\n",
      "\n",
      "River Bank\n",
      "tensor([50.9021, 50.3860, 43.6899, 40.3741, 35.7506, 32.1915, 30.5008, 27.7513])\n",
      "tensor([ 6631,  8993,  9768,  6071, 12149, 12559,  4197,  1692])\n"
     ]
    }
   ],
   "source": [
    "# print(torch.topk(shy.sae_acts[0][idx], k=8).indices)\n",
    "\n",
    "print(\"Wells Fargo Bank\")\n",
    "wf_indices = torch.topk(adventerous.sae_acts[0][idx], k=8).indices\n",
    "print(torch.topk(adventerous.sae_acts[0][idx], k=8).values)\n",
    "print(wf_indices)\n",
    "\n",
    "# 8993 -> terms related to banking and financial institutions\n",
    "# 15920 -> references to specific locations, sites or buildings\n",
    "\n",
    "print(\"\\nRiver Bank\")\n",
    "shy_5_indices = torch.topk(shy.sae_acts[0][idx], k=8).indices\n",
    "print(torch.topk(shy.sae_acts[0][idx], k=8).values)\n",
    "print(shy_5_indices)\n",
    "\n",
    "# 12149 -> references to natural landscapes and outdoor settings\n",
    "\n",
    "# shared features\n",
    "# 6693,9768,1692\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d24e93",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5b361272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "def get_dashboard_html(sae_release = \"gemma-2-2b\", sae_id=\"20-gemmascope-res-16k\", feature_idx=wf_indices[0]):\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0e517fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2304])\n",
      "torch.Size([16384])\n",
      "Number of non-empty activations: 46\n",
      "Cosine similarity between decoded and actual residual: 0.9462\n"
     ]
    }
   ],
   "source": [
    "# encoded residual is 16384, actual residual is 2304\n",
    "import torch.nn.functional as F\n",
    "\n",
    "token_idx = 1\n",
    "\n",
    "# adventerous = get_breakdown(\"i am a brave person.\", layer)\n",
    "\n",
    "# take the residual from the LLM and run it through the SAE\n",
    "actual_residual = adventerous.target_act[0][token_idx]\n",
    "print(actual_residual.shape)\n",
    "\n",
    "# the SAE has transformed the residual into a sparse representation. it has 16384 features, but only 77 are non-zero\n",
    "encoded_residual = adventerous.sae_acts[0][token_idx]\n",
    "\n",
    "# treescope.render_array(actual_residual)\n",
    "print(encoded_residual.shape)\n",
    "\n",
    "# only 46 of the 16384 are non-zero (hence \"SPARSE\")\n",
    "non_empty_activations = encoded_residual[encoded_residual != 0]\n",
    "print(f\"Number of non-empty activations: {len(non_empty_activations)}\")\n",
    "\n",
    "# Decode the encoded residual using the SAE class\n",
    "decoded_residual = sae.decode(encoded_residual.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "# Calculate cosine similarity between decoded and actual residual\n",
    "cosine_similarity = F.cosine_similarity(decoded_residual, actual_residual, dim=0)\n",
    "\n",
    "# This should be close to 1. Meaning, the SAE has done a good job at representing \n",
    "# the input residual as a linear combination of sparse features.\n",
    "print(f\"Cosine similarity between decoded and actual residual: {cosine_similarity.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "efd234f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_input(input_ids):\n",
    "  for i, t in enumerate(input_ids['input_ids'][0]):\n",
    "    print(f\"{i} Token {t}: \\t\\t{tokenizer.decode(t)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "07257861",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try to Shift the Meaning of river \"bank\" more toward \"Wells Fargo Bank\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a41c96",
   "metadata": {},
   "source": [
    "## Steering Time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55acec6b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "edd3a9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: I went to the river bank to\n"
     ]
    }
   ],
   "source": [
    "# First generate the output for input text river bank\n",
    "\n",
    "input_text2 = \"I went to the river bank\"\n",
    "# the first step is to tokenize the input text\n",
    "input_ids2 = tokenizer(input_text2, return_tensors=\"pt\", add_special_tokens=True)\n",
    "max_new_tokens = 1\n",
    "outputs2 = model.generate(**input_ids2, max_new_tokens=max_new_tokens)\n",
    "generated_text2 = tokenizer.decode(outputs2[0], skip_special_tokens=True)\n",
    "print(\"Generated text:\", generated_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0ab200e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script> (()=>{ if (customElements.get('treescope-container') === undefined) { class TreescopeContainer extends HTMLElement { constructor() { super(); this.attachShadow({mode: \"open\"}); this.defns = {}; this.state = {}; } } customElements.define(\"treescope-container\", TreescopeContainer); } if (customElements.get('treescope-run-here') === undefined) { class RunHere extends HTMLElement { constructor() { super() } connectedCallback() { const run = child => { const fn = new Function(child.textContent); child.textContent = \"\"; fn.call(this); this.remove(); }; const child = this.querySelector(\"script\"); if (child) { run(child); } else { new MutationObserver(()=>{ run(this.querySelector(\"script\")); }).observe(this, {childList: true}); } } } customElements.define(\"treescope-run-here\", RunHere); } })(); </script> <treescope-container class=\"treescope_out_1f3954c26d0b4548b688e93a353a8772\" ></treescope-container> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_1f3954c26d0b4548b688e93a353a8772\")) .filter((elt) => !elt.dataset.setup) )[0]; root.dataset.setup = 1; const msg = document.createElement(\"span\"); msg.style = \"color: #cccccc; font-family: monospace;\"; msg.textContent = \"(Loading...)\"; root.state.loadingMsg = msg; root.shadowRoot.appendChild(msg); root.state.chain = new Promise((resolve, reject) => { const observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); window.setTimeout(() => { observer.observe(root); }, 0); }); root.state.deferring = false; const _insertNode = (node) => { for (let oldScript of node.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } if (root.state.loadingMsg) { root.state.loadingMsg.remove(); root.state.loadingMsg = null; } root.shadowRoot.appendChild(node); }; root.defns.insertContent = ((contentNode, compressed) => { if (compressed) { root.state.deferring = true; } if (root.state.deferring) { root.state.chain = (async () => { await root.state.chain; if (compressed) { const encoded = contentNode.textContent; const blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); const reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); const parts = []; while (true) { const step = await reader.read(); if (step.done) { break; } parts.push(step.value); } const tpl = document.createElement('template'); tpl.innerHTML = parts.join(\"\"); _insertNode(tpl.content); } else { _insertNode(contentNode.content); } })(); } else { _insertNode(contentNode.content); } }); </script></treescope-run-here><div style=\"display:none\"> <script type=\"application/octet-stream\" >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</script> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_1f3954c26d0b4548b688e93a353a8772\")) .filter((elt) => !elt.dataset['step0']) )[0]; root.dataset['step0'] = 1; root.defns.insertContent( this.parentNode.querySelector('script[type=\"application/octet-stream\"]'), true ); this.parentNode.remove(); </script></treescope-run-here> </div>"
      ],
      "text/plain": [
       "<Arrayviz rendering>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8993 -> terms related to banking and financial institutions\n",
    "# 15920 -> references to specific locations, sites or buildings\n",
    "# scale values taken the SAE endcoder activations\n",
    "\n",
    "# more_bank = get_steering_vector(sae, torch.tensor([8893, 15920]), torch.tensor([73.0674, 42.8693]), 1)\n",
    "# \n",
    "more_bank = get_steering_vector(sae, torch.tensor([8893, 15920]), torch.tensor([73.0674, 42.8693]), 1)\n",
    "treescope.render_array(more_bank)   \n",
    "\n",
    "\n",
    "# 14377 -> phrases related to resilience and overcoming challenges\n",
    "# 10810 -> words related to safety and protection\n",
    "# 9644 -> phrases describing a player's capabilities and performance in basketball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "19030137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: I went to Wells Fargo Bank to open a checking account\n"
     ]
    }
   ],
   "source": [
    "# Next generate the output for input text Wells Fargo Bank\n",
    "\n",
    "input_text2 = \"I went to Wells Fargo Bank\"\n",
    "# the first step is to tokenize the input text\n",
    "input_ids2 = tokenizer(input_text2, return_tensors=\"pt\", add_special_tokens=True)\n",
    "max_new_tokens = 5\n",
    "outputs2 = model.generate(**input_ids2, max_new_tokens=max_new_tokens)\n",
    "generated_text2 = tokenizer.decode(outputs2[0], skip_special_tokens=True)\n",
    "print(\"Generated text:\", generated_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "18ab5cb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Tensor' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[237], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m modified_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodify_layer_activation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmore_bank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[236], line 31\u001b[0m, in \u001b[0;36mmodify_layer_activation\u001b[0;34m(model, target_layer, input_ids, steering, scale, max_new_tokens)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Run the model with the modified activation\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 31\u001b[0m     modified_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Remove the hook\u001b[39;00m\n\u001b[1;32m     34\u001b[0m handle\u001b[38;5;241m.\u001b[39mremove()\n",
      "File \u001b[0;32m~/Development/sae/myenv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/sae/myenv/lib/python3.10/site-packages/transformers/generation/utils.py:2048\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2040\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2041\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2042\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2043\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2044\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2045\u001b[0m     )\n\u001b[1;32m   2047\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2048\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2049\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2059\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2060\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2061\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2062\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2068\u001b[0m     )\n",
      "File \u001b[0;32m~/Development/sae/myenv/lib/python3.10/site-packages/transformers/generation/utils.py:3008\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3005\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3007\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3008\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3011\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/sae/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/sae/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/sae/myenv/lib/python3.10/site-packages/transformers/models/gemma2/modeling_gemma2.py:1047\u001b[0m, in \u001b[0;36mGemma2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m   1045\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1047\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n",
      "File \u001b[0;32m~/Development/sae/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/sae/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/sae/myenv/lib/python3.10/site-packages/transformers/models/gemma2/modeling_gemma2.py:890\u001b[0m, in \u001b[0;36mGemma2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    879\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    880\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    881\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         cache_position,\n\u001b[1;32m    888\u001b[0m     )\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 890\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/Development/sae/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/sae/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1616\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1614\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1616\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1619\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "Cell \u001b[0;32mIn[162], line 20\u001b[0m, in \u001b[0;36mmodify_layer_activation.<locals>.capture_and_modify_hook\u001b[0;34m(module, inputs, outputs)\u001b[0m\n\u001b[1;32m     18\u001b[0m original_act \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()        \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Decode the modified activations\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m modified_act \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_act\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteering\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Return the modified activation\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (modified_act,) \u001b[38;5;241m+\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Tensor' and 'list'"
     ]
    }
   ],
   "source": [
    "modified_output = modify_layer_activation(model, layer, shy.input_ids['input_ids'], more_bank, 100, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca6d0d3",
   "metadata": {},
   "source": [
    "generated_text2 = tokenizer.decode(modified_output[0], skip_special_tokens=True)\n",
    "print(\"Modified text:\", generated_text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4dbdd21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0062,  0.0144,  0.0147,  ...,  0.0015, -0.0042, -0.0066]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87485954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
