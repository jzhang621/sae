{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96d43e74-d62e-47d6-ad43-16b1a9cf98c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x131be5eb0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some notes from SAE tutorial on gemmascope https://colab.research.google.com/drive/17dQFYUYnuKnP6OwQPH9v_GSYUW5aj-Rp#scrollTo=12wF3f7o1Ni7\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.set_grad_enabled(False) # avoid blowing up mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbdbabc8-3254-48a6-b090-99d374fa61ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.48it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f178b0e3-65e5-4089-8445-9149d6dea35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to study what's happening in the model when we run some input text through it\n",
    "input_text = \"hello, Yoda my name is\"\n",
    "# the first step is to tokenize the input text\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce20d8e6-10db-49e3-a8a8-7b4649166708",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**input_ids, max_new_tokens=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84024761-2bea-4861-a252-a6e17e68ff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: hello, Yoda my name is Yoda and\n"
     ]
    }
   ],
   "source": [
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"Generated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e5d93dd-b496-4f62-a60c-0f38f186927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get hidden states, we need to run the model again with the generated sequence\n",
    "full_output = model(outputs[0].unsqueeze(0), output_hidden_states=True)\n",
    "\n",
    "# Access hidden states\n",
    "hidden_states = full_output.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4586dba-ee7b-4066-b5a3-d7ad869a27ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tokens 7\n",
      "output tokens 9\n",
      "hidden states (layers) 27\n",
      "hidden state shape torch.Size([1, 9, 2304])\n"
     ]
    }
   ],
   "source": [
    "# https://www.neuronpedia.org/gemma-2-2b/0-gemmascope-mlp-65k\n",
    "print(\"input tokens\", len(input_ids['input_ids'][0]))\n",
    "print(\"output tokens\", len(outputs[0]))\n",
    "print(\"hidden states (layers)\", len(hidden_states))\n",
    "print(\"hidden state shape\", hidden_states[20].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c13a7ee2-2a8a-45e6-a876-104c81393632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma2ForCausalLM(\n",
      "  (model): Gemma2Model(\n",
      "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-25): 26 x Gemma2DecoderLayer(\n",
      "        (self_attn): Gemma2Attention(\n",
      "          (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
      "          (rotary_emb): Gemma2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Gemma2MLP(\n",
      "          (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
      "          (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
      "          (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
      "          (act_fn): PytorchGELUTanh()\n",
      "        )\n",
      "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
      "  (_cache): HybridCache()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd979ed3-ee14-4236-9e66-712b03db0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in config: 26\n",
      "Hidden size: 2304\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of layers in config: {model.config.num_hidden_layers}\")\n",
    "print(f\"Hidden size: {model.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "204105f7-3966-46af-b46d-73e85386bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_residual_activations(model, target_layer, inputs):\n",
    "  \"\"\"\n",
    "  This function allows us to gather activations for a specific layer on a model.\n",
    "  \n",
    "  Args:\n",
    "  - model: The model from which we want to gather activations.\n",
    "  - target_layer: The specific layer index for which we want to gather activations.\n",
    "  - inputs: The input data to be passed through the model.\n",
    "  \n",
    "  Returns:\n",
    "  - target_act: The activations of the specified layer.\n",
    "  \"\"\"\n",
    "  target_act = None\n",
    "  def gather_target_act_hook(mod, inputs, outputs):\n",
    "    nonlocal target_act # make sure we can modify the target_act from the outer scope\n",
    "    target_act = outputs[0]\n",
    "    return outputs\n",
    "  # we could also easily target the MLP layer\n",
    "  # handle = model.model.layers[target_layer].mlp.register_forward_hook(gather_mlp_output_hook)\n",
    "  handle = model.model.layers[target_layer].register_forward_hook(gather_target_act_hook)\n",
    "  _ = model.forward(inputs)\n",
    "  handle.remove()\n",
    "  return target_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22c6262f-1c7d-4dfd-a6cc-14a3490bc77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 20th index is actually the 21st layer\n",
    "target_act = gather_residual_activations(model, 20, input_ids['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e639dadc-f54e-4d84-91ac-272850120c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 2304])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ff80810-e2ea-451f-b498-1a831452dcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9440,  1.7632, -2.0879,  ...,  1.6978, -2.0868, -0.0178],\n",
       "         [-7.1130,  2.3935, -0.3611,  ..., -0.0207,  4.9698,  2.0012],\n",
       "         [-8.1484,  0.2589, -0.5944,  ..., -1.2177,  2.7641,  2.0122],\n",
       "         ...,\n",
       "         [ 1.5289, -3.7196,  7.7939,  ..., -9.8385,  0.1159,  0.6954],\n",
       "         [-3.1761,  1.1008,  0.5456,  ..., -1.7524, -2.0917,  2.4893],\n",
       "         [ 0.9512, -2.4978, -0.4893,  ..., -4.7208, -5.6637, -0.7142]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_act\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f17bf69-7812-4ea3-b670-b54d33b07874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9440,  1.7632, -2.0879,  ...,  1.6978, -2.0868, -0.0178],\n",
       "         [-7.1130,  2.3935, -0.3611,  ..., -0.0207,  4.9698,  2.0012],\n",
       "         [-8.1484,  0.2589, -0.5944,  ..., -1.2177,  2.7640,  2.0122],\n",
       "         ...,\n",
       "         [ 0.9512, -2.4978, -0.4893,  ..., -4.7208, -5.6637, -0.7142],\n",
       "         [-4.1288,  3.6604,  4.8044,  ..., -5.9026,  3.5426,  0.6035],\n",
       "         [-1.2318, -1.7791, -1.2568,  ..., -0.5708,  7.3362,  1.7607]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[21]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d267c777-e51e-45db-a0c9-e6dd8771a7d9",
   "metadata": {},
   "source": [
    "## SAE Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "452ad63e-0bc9-489d-890b-0b836dc366f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download, notebook_login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bdd91dd5-a254-4d1d-86e2-c6916b20d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_params = hf_hub_download(\n",
    "    repo_id=\"google/gemma-scope-2b-pt-res\",\n",
    "    filename=\"layer_20/width_16k/average_l0_71/params.npz\",\n",
    "    force_download=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d641c161-241e-47ab-9bd0-9861341d6ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v) for k, v in params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c90a01f8-1fba-44a5-9060-7c302223a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class JumpReLUSAE(nn.Module):\n",
    "  def __init__(self, d_model, d_sae):\n",
    "    # Note that we initialise these to zeros because we're loading in pre-trained weights.\n",
    "    # If you want to train your own SAEs then we recommend using blah\n",
    "    super().__init__()\n",
    "    self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "    self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "    self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "    self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "    self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "  def encode(self, input_acts):\n",
    "    pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "    mask = (pre_acts > self.threshold)\n",
    "    acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "    return acts\n",
    "\n",
    "  def decode(self, acts):\n",
    "    return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "  def forward(self, acts):\n",
    "    acts = self.encode(acts)\n",
    "    recon = self.decode(acts)\n",
    "    return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ad51a15-53bd-40ec-bd07-d1c090b939db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['W_enc'].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d311f578-9373-48ad-80ef-c0d704ae53c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 2304])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c539e0b6-0fce-4b60-ac29-101e9747c76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69e5ebfc-f9f8-43c2-8c67-33583c4baa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sae_acts = sae.encode(target_act.to(torch.float32))\n",
    "reconstruction = sae.decode(sae_acts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "47a30b6b-72c3-4a1d-91ca-c8041aa2902b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 16384])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_acts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99629a09-f9dc-4631-91a2-7c436aabe06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 2304])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "05e31295-4435-4e69-ad48-9d2e7876caef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.6748e+01,  2.3060e+02, -1.3471e+02,  ...,  4.2310e+02,\n",
       "          -5.1567e+01, -1.9870e+01],\n",
       "         [-2.6197e+00,  7.4656e+00, -9.5365e-01,  ...,  2.9511e-01,\n",
       "           5.8423e+00, -1.1159e+00],\n",
       "         [-6.9128e+00,  2.1571e+00, -8.5115e-02,  ..., -2.4720e-01,\n",
       "           1.4987e+00, -1.6939e+00],\n",
       "         ...,\n",
       "         [ 1.1387e+00, -5.9275e+00,  5.5095e+00,  ..., -4.9588e+00,\n",
       "          -1.1925e-01,  3.7750e+00],\n",
       "         [-5.8372e-01, -2.8277e+00,  1.3489e+00,  ..., -4.8409e+00,\n",
       "           1.5609e+00,  5.4106e+00],\n",
       "         [-1.3586e+00, -2.0193e+00, -1.3169e+00,  ..., -1.5933e+00,\n",
       "          -8.7615e-01,  1.0083e+00]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c545ee2b-d5b0-4f49-a10b-a8765c1ed1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6631, 14956, 10299, 15449, 11302,  8564, 15449]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, inds = sae_acts.max(-1)\n",
    "\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e84caabf-5895-405d-a5e9-5fe9796747f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9440,  1.7632, -2.0879,  ...,  1.6978, -2.0868, -0.0178],\n",
       "         [-7.1130,  2.3935, -0.3611,  ..., -0.0207,  4.9698,  2.0012],\n",
       "         [-8.1484,  0.2589, -0.5944,  ..., -1.2177,  2.7641,  2.0122],\n",
       "         ...,\n",
       "         [ 1.5289, -3.7196,  7.7939,  ..., -9.8385,  0.1159,  0.6954],\n",
       "         [-3.1761,  1.1008,  0.5456,  ..., -1.7524, -2.0917,  2.4893],\n",
       "         [ 0.9512, -2.4978, -0.4893,  ..., -4.7208, -5.6637, -0.7142]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b8cd4b65-ee27-472e-b59f-e4f12b938cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2028.7983,  122.3900,  107.6448,   90.2571,   89.6321,  102.8196,\n",
       "           42.7972]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2c5d5fc2-b123-4fab-8667-091817be06d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 values shape: torch.Size([1, 7, 5])\n",
      "Top 5 indices shape: torch.Size([1, 7, 5])\n",
      "\n",
      "Top 5 values for first sequence item:\n",
      "tensor([2028.7983,  781.3959,  534.8594,  264.1917,  252.5279])\n",
      "\n",
      "Top 5 indices for first sequence item:\n",
      "tensor([ 6631,   743,  5052, 16057,  9479])\n"
     ]
    }
   ],
   "source": [
    "k = 5  # Change this to the number of top values you want\n",
    "values, indices = torch.topk(sae_acts, k, dim=-1)\n",
    "\n",
    "print(f\"Top {k} values shape: {values.shape}\")\n",
    "print(f\"Top {k} indices shape: {indices.shape}\")\n",
    "\n",
    "# Print the top k values and indices for the first sequence item\n",
    "print(f\"\\nTop {k} values for first sequence item:\")\n",
    "print(values[0, 0])\n",
    "print(f\"\\nTop {k} indices for first sequence item:\")\n",
    "print(indices[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3081f9bf-67b8-4c0b-a868-5c10519b2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import IFrame\n",
    "html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "def get_dashboard_html(sae_release = \"gemma-2-2b\", sae_id=\"20-gemmascope-res-16k\", feature_idx=0):\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f92802e-0b88-43e1-954e-623fb3a636a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1200\"\n",
       "            src=\"https://neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/8564?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1307a4070>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = get_dashboard_html(sae_release = \"gemma-2-2b\", sae_id=\"20-gemmascope-res-16k\", feature_idx=8564)\n",
    "IFrame(html, width=1200, height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f58fc30-288b-486a-a2b1-356dd04def06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_layer_activation(model, target_layer, input_ids, sae, feature_index, modification_value, max_new_tokens):\n",
    "    \"\"\"\n",
    "    Modify the activation of a specific feature in a given layer.\n",
    "    \n",
    "    Args:\n",
    "    - model: The LLM model\n",
    "    - target_layer: The index of the layer to modify\n",
    "    - input_ids: The input token IDs\n",
    "    - sae: The Sparse Autoencoder\n",
    "    - feature_index: The index of the feature to modify\n",
    "    - modification_value: The value to add to the feature's activation\n",
    "    \n",
    "    Returns:\n",
    "    - modified_output: The model's output after modification\n",
    "    \"\"\"\n",
    "    def capture_and_modify_hook(module, inputs, outputs):\n",
    "        # Capture the original activation\n",
    "        original_act = outputs[0].detach()\n",
    "        \n",
    "        # Encode the activations using the SAE\n",
    "        sae_acts = sae.encode(original_act.to(torch.float32))\n",
    "        \n",
    "        # Modify the specific feature's activation\n",
    "        sae_acts[0, :, feature_index] += modification_value\n",
    "        \n",
    "        # Decode the modified activations\n",
    "        modified_act = sae.decode(sae_acts)\n",
    "        \n",
    "        # Return the modified activation\n",
    "        return (modified_act,) + outputs[1:]\n",
    "\n",
    "    # Register the hook\n",
    "    handle = model.model.layers[target_layer].register_forward_hook(capture_and_modify_hook)\n",
    "    \n",
    "    # Run the model with the modified activation\n",
    "    with torch.no_grad():\n",
    "        modified_output = model.generate(input_ids, max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # Remove the hook\n",
    "    handle.remove()\n",
    "    \n",
    "    return modified_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9520f580-6b0a-441d-afd8-245876ef7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to study what's happening in the model when we run some input text through it\n",
    "input_text2 = \"Hello, my name is\"\n",
    "# the first step is to tokenize the input text\n",
    "input_ids2 = tokenizer(input_text2, return_tensors=\"pt\", add_special_tokens=True)\n",
    "max_new_tokens = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4607124-7062-469f-be2c-54600a5ff82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs2 = model.generate(**input_ids2, max_new_tokens=max_new_tokens)\n",
    "generated_text2 = tokenizer.decode(outputs2[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be6e492e-634f-46f8-8318-c82b6daf97b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Hello, my name is Dr. David and I'm a professor of\n",
      "Modified text: Hello, my name is Luke Skywalker Skywalker Skywalker Skywalker Skywalker Skywalker Skywalker Skywalker Skywalker\n"
     ]
    }
   ],
   "source": [
    "target_layer = 20  # The layer you want to modify\n",
    "feature_index = 15449  # The feature index you want to modify\n",
    "modification_value = 1000.0  # The value to add to the feature's activation\n",
    "\n",
    "modified_output = modify_layer_activation(model, target_layer, input_ids2['input_ids'], sae, feature_index, modification_value, max_new_tokens)\n",
    "\n",
    "# Generate text from the modified output\n",
    "modified_text = tokenizer.decode(modified_output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Original text:\", generated_text2)\n",
    "print(\"Modified text:\", modified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f793ba3-2b4e-434d-81cc-0e1174553643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
